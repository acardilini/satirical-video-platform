# LLM Configuration
# Choose your LLM provider: openai, anthropic, gemini, or local
LLM_PROVIDER=openai

# API Keys (only set the one you're using)
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
GEMINI_API_KEY=your_gemini_api_key_here

# LLM Model Configuration
LLM_MODEL=gpt-4
# For OpenAI: gpt-4, gpt-4-turbo, gpt-3.5-turbo
# For Anthropic: claude-3-sonnet-20240229, claude-3-haiku-20240307, claude-3-opus-20240229
# For Gemini: gemini-1.5-pro, gemini-1.5-flash, gemini-pro
# For local: llama2, mistral, etc.

# Local LLM Configuration (if using local provider)
LLM_BASE_URL=http://localhost:11434

# Other settings
NODE_ENV=development